{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成图像数据文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"garbageGAN/datasets/data\",exist_ok=True)\n",
    "os.makedirs(\"garbageGAN/datasets/data/trainA\",exist_ok=True)\n",
    "os.makedirs(\"garbageGAN/datasets/data/trainB\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/VOCdevkit\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/VOCdevkit/VOC2007\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/VOCdevkit/VOC2007/Annotations\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/VOCdevkit/VOC2007/JPEGImages\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/VOCdevkit/VOC2007/ImageSets\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/VOCdevkit/VOC2007/ImageSets/Main\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/test\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/test/VOC2007\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/test/VOC2007/Annotations\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/test/VOC2007/JPEGImages\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/test/VOC2007/ImageSets\",exist_ok=True)\n",
    "os.makedirs(\"yolox-pytorch/test/VOC2007/ImageSets/Main\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理图像数据集\n",
    "将图像数据复制进garbagrGAN项目和yolox项目对应的数据位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "S_dir=\"PersonDetect/S\"\n",
    "T_dir=\"PersonDetect/T\"\n",
    "img_files=os.listdir(os.path.join(S_dir,\"imgs\"))\n",
    "xml_files=os.listdir(os.path.join(S_dir,\"xml\"))\n",
    "s=0\n",
    "for i in img_files:\n",
    "    s=s+1\n",
    "    name=i.split(\".\")[0]\n",
    "    oldpath=os.path.join(S_dir,\"imgs\",i)  \n",
    "    newpath=os.path.join(\"garbageGAN/datasets/PersonDetect/trainA\",i)\n",
    "    if s<=500:shutil.copy(oldpath,newpath)\n",
    "    \n",
    "    oldpath=os.path.join(S_dir,\"imgs\",i)  \n",
    "    newpath=os.path.join(\"yolox-pytorch/VOCdevkit/VOC2007/JPEGImages\",i)\n",
    "    shutil.copy(oldpath,newpath)\n",
    "    \n",
    "    oldpath=os.path.join(S_dir,\"xml\",name+\".xml\")  \n",
    "    newpath=os.path.join(\"yolox-pytorch/VOCdevkit/VOC2007/Annotations\",name+\".xml\")\n",
    "    shutil.copy(oldpath,newpath)\n",
    "\n",
    "img_files=os.listdir(os.path.join(T_dir,\"imgs\"))\n",
    "xml_files=os.listdir(os.path.join(T_dir,\"xml\"))\n",
    "for i in img_files:\n",
    "    name=i.split(\".\")[0]\n",
    "    oldpath=os.path.join(T_dir,\"imgs\",i)  \n",
    "    newpath=os.path.join(\"garbageGAN/datasets/PersonDetect/trainB\",i)\n",
    "    shutil.copy(oldpath,newpath)\n",
    "    \n",
    "    oldpath=os.path.join(T_dir,\"imgs\",i)  \n",
    "    newpath=os.path.join(\"yolox-pytorch/test/VOC2007/JPEGImages\",i)\n",
    "    shutil.copy(oldpath,newpath)\n",
    "    \n",
    "    oldpath=os.path.join(T_dir,\"xml\",name+\".xml\")  \n",
    "    newpath=os.path.join(\"yolox-pytorch/test/VOC2007/Annotations\",name+\".xml\")\n",
    "    shutil.copy(oldpath,newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\VSCODE\\garbageGAN\\garbageGAN\n"
     ]
    }
   ],
   "source": [
    "cd garbageGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练garbageGAN模型\n",
    "\n",
    "--dataroot 数据集位置，数据集文件结果为dataset/trainA，dataset/trainB，迁移方向为A->B,若要训练其它数据集，需设置同样的文件夹格式\n",
    "\n",
    "--name 保存各个世代模型文件以及训练日志的位置，后续测试时会选择该文件夹下的latest_net_G.pth作为迁移模型\n",
    "\n",
    "具体的各个参数的解释在garbageGAN\\options文件夹下\n",
    "\n",
    "需要注意的是，模型训练需要创建一个visdom接口，如果没有开启的话会一直卡在这一步，开启时等候时间可能过长，需要对visdom的库文件进行操作，网上有相关教程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                 CUT_mode: CUT                           \n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "                    beta2: 0.999                         \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/PersonDetect       \t[default: placeholder]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: None                          \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "               easy_label: experiment_name               \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "          evaluation_freq: 5000                          \n",
      "        flip_equivariance: False                         \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: xavier                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "               lambda_GAN: 1.0                           \n",
      "               lambda_NCE: 1.0                           \n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cut                           \n",
      "                 n_epochs: 200                           \n",
      "           n_epochs_decay: 200                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: PD_garbageGAN                 \t[default: experiment_name]\n",
      "                    nce_T: 0.07                          \n",
      "                  nce_idt: True                          \n",
      "nce_includes_all_negatives_from_minibatch: False                         \n",
      "               nce_layers: 0,4,8,12,16                   \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netF: mlp_sample                    \n",
      "                  netF_nc: 256                           \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "             no_antialias: False                         \n",
      "          no_antialias_up: False                         \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                    normD: instance                      \n",
      "                    normG: instance                      \n",
      "              num_patches: 256                           \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "          pretrained_name: None                          \n",
      "               print_freq: 100                           \n",
      "         random_scale_max: 3.0                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "stylegan2_G_num_downsampling: 1                             \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "model [CUTModel] was created\n",
      "The number of training images = 1144\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: d:\\py39\\python.exe -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory ./checkpoints\\PD_garbageGAN\\web...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\connection.py\", line 203, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\connectionpool.py\", line 790, in urlopen\n",
      "    response = self._make_request(\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\connectionpool.py\", line 496, in _make_request\n",
      "    conn.request(\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\connection.py\", line 395, in request\n",
      "    self.endheaders()\n",
      "  File \"d:\\py39\\lib\\http\\client.py\", line 1274, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"d:\\py39\\lib\\http\\client.py\", line 1034, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"d:\\py39\\lib\\http\\client.py\", line 974, in send\n",
      "    self.connect()\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\connection.py\", line 243, in connect\n",
      "    self.sock = self._new_conn()\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\connection.py\", line 218, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001E5B3660400>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\py39\\lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\connectionpool.py\", line 844, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"d:\\py39\\lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E5B3660400>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\py39\\lib\\site-packages\\visdom\\__init__.py\", line 756, in _send\n",
      "    return self._handle_post(\n",
      "  File \"d:\\py39\\lib\\site-packages\\visdom\\__init__.py\", line 720, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"d:\\py39\\lib\\site-packages\\requests\\sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "  File \"d:\\py39\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"d:\\py39\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"d:\\py39\\lib\\site-packages\\requests\\adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001E5B3660400>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "on_close() takes 1 positional argument but 3 were given\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
      "\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\VSCODE\\garbageGAN\\garbageGAN\\train.py\", line 31, in <module>\n",
      "    for i, data in enumerate(dataset):  # inner loop within one epoch\n",
      "  File \"f:\\VSCODE\\garbageGAN\\garbageGAN\\data\\__init__.py\", line 95, in __iter__\n",
      "    for i, data in enumerate(self.dataloader):\n",
      "  File \"d:\\py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"d:\\py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"d:\\py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1034, in __init__\n",
      "    w.start()\n",
      "  File \"d:\\py39\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"d:\\py39\\lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"d:\\py39\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"d:\\py39\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"d:\\py39\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle '_thread.lock' object\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"d:\\py39\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"d:\\py39\\lib\\multiprocessing\\spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "EOFError: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ./datasets/PersonDetect --name PD_garbageGAN  --model garbageGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择迁移模型\n",
    "\n",
    "经过测试，发现迁移模型在epoch=200的时候迁移图像的效果较好，所以选择该模型文件作为迁移模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp checkpoints/PD_garbageGAN/200_net_G.pth  checkpoints/PD_garbageGAN/latest_net_G.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成迁移后的图像\n",
    "-- num_test 迁移图像数量，课题里为trainA的所有图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                 CUT_mode: CUT                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/PersonDetect       \t[default: placeholder]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "               easy_label: experiment_name               \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "        flip_equivariance: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: xavier                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "               lambda_GAN: 1.0                           \n",
      "               lambda_NCE: 1.0                           \n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cut                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: PD_garbageGAN                 \t[default: experiment_name]\n",
      "                    nce_T: 0.07                          \n",
      "                  nce_idt: True                          \n",
      "nce_includes_all_negatives_from_minibatch: False                         \n",
      "               nce_layers: 0,4,8,12,16                   \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netF: mlp_sample                    \n",
      "                  netF_nc: 256                           \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "             no_antialias: False                         \n",
      "          no_antialias_up: False                         \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                    normD: instance                      \n",
      "                    normG: instance                      \n",
      "              num_patches: 256                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \t[default: test]\n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "         random_scale_max: 3.0                           \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "stylegan2_G_num_downsampling: 1                             \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "dataset [UnalignedDataset] was created\n",
      "model [CUTModel] was created\n",
      "creating web directory ./results/PD_garbageGAN/train_latest\n",
      "loading the model from ./checkpoints/PD_garbageGAN/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.378 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-1.jpg']\n",
      "processing (0005)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-103.jpg']\n",
      "processing (0010)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-108.jpg']\n",
      "processing (0015)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-112.jpg']\n",
      "processing (0020)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-117.jpg']\n",
      "processing (0025)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-121.jpg']\n",
      "processing (0030)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-126.jpg']\n",
      "processing (0035)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-130.jpg']\n",
      "processing (0040)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-135.jpg']\n",
      "processing (0045)-th image... ['./datasets/PersonDetect/trainA/AlertSampleD-14.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot ./datasets/PersonDetect --name PD_garbageGAN  --phase train --model garbageGAN --num_test 1144 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ϵͳ�Ҳ���ָ����·����\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd yolox-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成训练目标检测模型的图像文件索引\n",
    "若要训练自己的数据集需要在voc_annotation.py里更改class文件位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate txt in ImageSets.\n",
      "train and val size 1029\n",
      "train size 926\n",
      "Generate txt in ImageSets done.\n",
      "Generate 2007_train.txt and 2007_val.txt for train.\n",
      "Generate 2007_train.txt and 2007_val.txt for train done.\n",
      "|       worker | 1001 | \n",
      "|       person | 1152 | \n",
      "|    zhizhipin |  950 | \n",
      "| suliaozhipin |  717 | \n",
      "|     lvzhipin |  248 | \n",
      "|      garbage |   59 | \n",
      "|  garbage-bag |  779 | \n",
      "|   mianzhipin |   28 | \n",
      "|  paomozhipin |  142 | \n",
      "|      youtong |   38 | \n",
      "|     bumingwu |    2 | \n"
     ]
    }
   ],
   "source": [
    "!python voc_annotation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练目标检测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成计算评估指标的验证集索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fp=open(r\"test/VOC2007/ImageSets/Main/test.txt\",\"w\")\n",
    "imgdir=r\"test/VOC2007/JPEGImages\"\n",
    "files=os.listdir(imgdir)\n",
    "for i in files:\n",
    "    name=i.split(\".\")[0]\n",
    "    fp.write(name+\"\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算评估指标\n",
    "计算迁移前目标检测模型的mAP以及AP指标\n",
    "\n",
    "需要在yolox-pytorch\\yolo.py文件里修改模型文件位置\n",
    "\n",
    "模型文件储存在yolox-pytorch\\logs文件夹里面\n",
    "\n",
    "计算结果默认保存在yolox-pytorch\\map_out文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python get_map.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理迁移后图像的脚本\n",
    "\n",
    "将迁移后的图像加入到目标检测模型训练集中，并生成对应的标注文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 14-15: truncated \\xXX escape (3988472180.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    S_xmldir=\"PersonDetect\\S\\xml\"\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 14-15: truncated \\xXX escape\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "imgdir=\"yolox-pytorch/VOCdevkit/VOC2007/JPEGImages\"\n",
    "xmldir=\"yolox-pytorch/VOCdevkit/VOC2007/Annotations\"\n",
    "T_imgdir=\"garbageGAN/results/PD_garbageGAN/train_latest/images/fake_B\"\n",
    "S_imgdir=r\"PersonDetect/S/imgs\"\n",
    "S_xmldir=r\"PersonDetect/S/xml\"\n",
    "\n",
    "files=os.listdir(T_imgdir)\n",
    "for i in files:\n",
    "    name=i.split(\".\")[0]\n",
    "    oldname=os.path.join(T_imgdir,i)\n",
    "    newname=os.path.join(imgdir,name+\"_fake.jpg\")\n",
    "    shutil.copy(oldname,newname)\n",
    "    oldname=os.path.join(S_xmldir,name+\".xml\")\n",
    "    newname=os.path.join(xmldir,name+\"_fake.xml\")\n",
    "    shutil.copy(oldname,newname)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再次训练目标检测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ������ F �еľ��� �¼Ӿ�\n",
      " �������к��� 3280-EA76\n",
      "\n",
      " f:\\VSCODE\\garbageGAN\\yolox-pytorch ��Ŀ¼\n",
      "\n",
      "2024/05/17  19:22    <DIR>          .\n",
      "2024/05/17  18:08    <DIR>          ..\n",
      "2024/05/17  18:08    <DIR>          .git\n",
      "2024/05/11  12:54             1,925 .gitignore\n",
      "2024/05/17  18:08    <DIR>          .ipynb_checkpoints\n",
      "2024/05/12  23:21           342,998 2007_train.txt\n",
      "2024/05/12  23:21            38,219 2007_val.txt\n",
      "2024/05/17  19:16             8,287 get_map.py\n",
      "2024/05/17  18:08    <DIR>          img\n",
      "2024/05/11  12:54            11,347 LICENSE\n",
      "2024/05/17  19:22    <DIR>          logs\n",
      "2024/05/17  18:08    <DIR>          model_data\n",
      "2024/05/17  18:08    <DIR>          nets\n",
      "2024/05/11  12:54             9,355 predict.py\n",
      "2024/05/11  12:54            10,792 README.md\n",
      "2024/05/11  12:54               147 requirements.txt\n",
      "2024/05/11  12:54             1,368 summary.py\n",
      "2024/05/17  18:36    <DIR>          test\n",
      "2024/05/12  23:22            32,516 train.py\n",
      "2024/05/17  18:08    <DIR>          utils\n",
      "2024/05/17  18:08    <DIR>          utils_coco\n",
      "2024/05/17  19:13             7,547 voc_annotation.py\n",
      "2024/05/17  18:24    <DIR>          VOCdevkit\n",
      "2024/05/17  19:17            21,505 yolo.py\n",
      "2024/05/11  12:54            45,474 �����������.md\n",
      "              13 ���ļ�        531,480 �ֽ�\n",
      "              12 ��Ŀ¼ 3,372,275,728,384 �����ֽ�\n"
     ]
    }
   ],
   "source": [
    "cd yolox-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python voc_annotation.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算利用迁移后的图像数据集训练的目标检测模型的指标\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python get_map.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
